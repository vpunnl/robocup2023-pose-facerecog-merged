{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdataset.csv\u001b[39m\u001b[39m'\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('dataset.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "66/66 [==============================] - 0s 5ms/step - loss: -6740920.5000 - accuracy: 0.2347 - val_loss: -7347542.5000 - val_accuracy: 0.2347\n",
      "Epoch 2/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: -8245843.0000 - accuracy: 0.2347 - val_loss: -8890949.0000 - val_accuracy: 0.2347\n",
      "Epoch 3/300\n",
      "66/66 [==============================] - 0s 5ms/step - loss: -9929067.0000 - accuracy: 0.2347 - val_loss: -10674003.0000 - val_accuracy: 0.2347\n",
      "Epoch 4/300\n",
      "66/66 [==============================] - 0s 4ms/step - loss: -11831401.0000 - accuracy: 0.2347 - val_loss: -12636298.0000 - val_accuracy: 0.2347\n",
      "Epoch 5/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -13947330.0000 - accuracy: 0.2347 - val_loss: -14806656.0000 - val_accuracy: 0.2347\n",
      "Epoch 6/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -16267371.0000 - accuracy: 0.2347 - val_loss: -17192762.0000 - val_accuracy: 0.2347\n",
      "Epoch 7/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -18816036.0000 - accuracy: 0.2347 - val_loss: -19834372.0000 - val_accuracy: 0.2347\n",
      "Epoch 8/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -21603122.0000 - accuracy: 0.2347 - val_loss: -22680250.0000 - val_accuracy: 0.2347\n",
      "Epoch 9/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -24623718.0000 - accuracy: 0.2347 - val_loss: -25755190.0000 - val_accuracy: 0.2347\n",
      "Epoch 10/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -27907724.0000 - accuracy: 0.2347 - val_loss: -29065052.0000 - val_accuracy: 0.2347\n",
      "Epoch 11/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -31437162.0000 - accuracy: 0.2347 - val_loss: -32626496.0000 - val_accuracy: 0.2347\n",
      "Epoch 12/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -35171932.0000 - accuracy: 0.2347 - val_loss: -36498148.0000 - val_accuracy: 0.2347\n",
      "Epoch 13/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -39188388.0000 - accuracy: 0.2347 - val_loss: -40461440.0000 - val_accuracy: 0.2347\n",
      "Epoch 14/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -43437984.0000 - accuracy: 0.2347 - val_loss: -44852044.0000 - val_accuracy: 0.2347\n",
      "Epoch 15/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -47956040.0000 - accuracy: 0.2347 - val_loss: -49366348.0000 - val_accuracy: 0.2347\n",
      "Epoch 16/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -52749768.0000 - accuracy: 0.2347 - val_loss: -54172652.0000 - val_accuracy: 0.2347\n",
      "Epoch 17/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -57812424.0000 - accuracy: 0.2347 - val_loss: -59280304.0000 - val_accuracy: 0.2347\n",
      "Epoch 18/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -63172500.0000 - accuracy: 0.2347 - val_loss: -64732192.0000 - val_accuracy: 0.2347\n",
      "Epoch 19/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -68819448.0000 - accuracy: 0.2347 - val_loss: -70392752.0000 - val_accuracy: 0.2347\n",
      "Epoch 20/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -74787304.0000 - accuracy: 0.2347 - val_loss: -76339832.0000 - val_accuracy: 0.2347\n",
      "Epoch 21/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -81014472.0000 - accuracy: 0.2347 - val_loss: -82681864.0000 - val_accuracy: 0.2347\n",
      "Epoch 22/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -87508008.0000 - accuracy: 0.2347 - val_loss: -89110464.0000 - val_accuracy: 0.2347\n",
      "Epoch 23/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -94266816.0000 - accuracy: 0.2347 - val_loss: -95847208.0000 - val_accuracy: 0.2347\n",
      "Epoch 24/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -101351064.0000 - accuracy: 0.2347 - val_loss: -102945216.0000 - val_accuracy: 0.2347\n",
      "Epoch 25/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -108739592.0000 - accuracy: 0.2347 - val_loss: -110353576.0000 - val_accuracy: 0.2347\n",
      "Epoch 26/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -116442224.0000 - accuracy: 0.2347 - val_loss: -118063344.0000 - val_accuracy: 0.2347\n",
      "Epoch 27/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -124477016.0000 - accuracy: 0.2347 - val_loss: -126228312.0000 - val_accuracy: 0.2347\n",
      "Epoch 28/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -133052728.0000 - accuracy: 0.2347 - val_loss: -134630064.0000 - val_accuracy: 0.2347\n",
      "Epoch 29/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -141978032.0000 - accuracy: 0.2347 - val_loss: -143691088.0000 - val_accuracy: 0.2347\n",
      "Epoch 30/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -151311184.0000 - accuracy: 0.2347 - val_loss: -153106240.0000 - val_accuracy: 0.2347\n",
      "Epoch 31/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -161059456.0000 - accuracy: 0.2347 - val_loss: -162805088.0000 - val_accuracy: 0.2347\n",
      "Epoch 32/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -171101536.0000 - accuracy: 0.2347 - val_loss: -172825648.0000 - val_accuracy: 0.2347\n",
      "Epoch 33/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -181421200.0000 - accuracy: 0.2347 - val_loss: -183197296.0000 - val_accuracy: 0.2347\n",
      "Epoch 34/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -192035808.0000 - accuracy: 0.2347 - val_loss: -193700080.0000 - val_accuracy: 0.2347\n",
      "Epoch 35/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -203069056.0000 - accuracy: 0.2347 - val_loss: -204670656.0000 - val_accuracy: 0.2347\n",
      "Epoch 36/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -214455248.0000 - accuracy: 0.2347 - val_loss: -216051120.0000 - val_accuracy: 0.2347\n",
      "Epoch 37/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -226280896.0000 - accuracy: 0.2347 - val_loss: -227848944.0000 - val_accuracy: 0.2347\n",
      "Epoch 38/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -238489424.0000 - accuracy: 0.2347 - val_loss: -239770976.0000 - val_accuracy: 0.2347\n",
      "Epoch 39/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -251003984.0000 - accuracy: 0.2347 - val_loss: -252401888.0000 - val_accuracy: 0.2347\n",
      "Epoch 40/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -264046016.0000 - accuracy: 0.2347 - val_loss: -265484304.0000 - val_accuracy: 0.2347\n",
      "Epoch 41/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -277375712.0000 - accuracy: 0.2347 - val_loss: -278583904.0000 - val_accuracy: 0.2347\n",
      "Epoch 42/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -290908800.0000 - accuracy: 0.2347 - val_loss: -291872224.0000 - val_accuracy: 0.2347\n",
      "Epoch 43/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -304862208.0000 - accuracy: 0.2347 - val_loss: -305882688.0000 - val_accuracy: 0.2347\n",
      "Epoch 44/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -319120480.0000 - accuracy: 0.2347 - val_loss: -320135360.0000 - val_accuracy: 0.2347\n",
      "Epoch 45/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -333955680.0000 - accuracy: 0.2347 - val_loss: -334694368.0000 - val_accuracy: 0.2347\n",
      "Epoch 46/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -349124352.0000 - accuracy: 0.2347 - val_loss: -350048256.0000 - val_accuracy: 0.2347\n",
      "Epoch 47/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -364761792.0000 - accuracy: 0.2347 - val_loss: -365601344.0000 - val_accuracy: 0.2347\n",
      "Epoch 48/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -380786080.0000 - accuracy: 0.2347 - val_loss: -381193280.0000 - val_accuracy: 0.2347\n",
      "Epoch 49/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -397031648.0000 - accuracy: 0.2347 - val_loss: -397374976.0000 - val_accuracy: 0.2347\n",
      "Epoch 50/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -413762400.0000 - accuracy: 0.2347 - val_loss: -414104352.0000 - val_accuracy: 0.2347\n",
      "Epoch 51/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -431035104.0000 - accuracy: 0.2347 - val_loss: -430938784.0000 - val_accuracy: 0.2347\n",
      "Epoch 52/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -448640448.0000 - accuracy: 0.2347 - val_loss: -448741696.0000 - val_accuracy: 0.2347\n",
      "Epoch 53/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -466747456.0000 - accuracy: 0.2347 - val_loss: -466580544.0000 - val_accuracy: 0.2347\n",
      "Epoch 54/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -485121504.0000 - accuracy: 0.2347 - val_loss: -484646208.0000 - val_accuracy: 0.2347\n",
      "Epoch 55/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -503785280.0000 - accuracy: 0.2347 - val_loss: -503108960.0000 - val_accuracy: 0.2347\n",
      "Epoch 56/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -522980928.0000 - accuracy: 0.2347 - val_loss: -522465344.0000 - val_accuracy: 0.2347\n",
      "Epoch 57/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -542700032.0000 - accuracy: 0.2347 - val_loss: -541865280.0000 - val_accuracy: 0.2347\n",
      "Epoch 58/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -562618304.0000 - accuracy: 0.2347 - val_loss: -561517568.0000 - val_accuracy: 0.2347\n",
      "Epoch 59/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -583114432.0000 - accuracy: 0.2347 - val_loss: -581861184.0000 - val_accuracy: 0.2347\n",
      "Epoch 60/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -604151616.0000 - accuracy: 0.2347 - val_loss: -602656576.0000 - val_accuracy: 0.2347\n",
      "Epoch 61/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -625323648.0000 - accuracy: 0.2347 - val_loss: -623539520.0000 - val_accuracy: 0.2347\n",
      "Epoch 62/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -646784448.0000 - accuracy: 0.2347 - val_loss: -644965696.0000 - val_accuracy: 0.2347\n",
      "Epoch 63/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -668611392.0000 - accuracy: 0.2347 - val_loss: -666731392.0000 - val_accuracy: 0.2347\n",
      "Epoch 64/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -690898240.0000 - accuracy: 0.2347 - val_loss: -688426432.0000 - val_accuracy: 0.2347\n",
      "Epoch 65/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -713600000.0000 - accuracy: 0.2347 - val_loss: -710986880.0000 - val_accuracy: 0.2347\n",
      "Epoch 66/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -737074624.0000 - accuracy: 0.2347 - val_loss: -734383232.0000 - val_accuracy: 0.2347\n",
      "Epoch 67/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -761003264.0000 - accuracy: 0.2347 - val_loss: -757630976.0000 - val_accuracy: 0.2347\n",
      "Epoch 68/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -785046272.0000 - accuracy: 0.2347 - val_loss: -781759040.0000 - val_accuracy: 0.2347\n",
      "Epoch 69/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -809780288.0000 - accuracy: 0.2347 - val_loss: -805874112.0000 - val_accuracy: 0.2347\n",
      "Epoch 70/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -834841344.0000 - accuracy: 0.2347 - val_loss: -830581888.0000 - val_accuracy: 0.2347\n",
      "Epoch 71/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -860418368.0000 - accuracy: 0.2347 - val_loss: -856417856.0000 - val_accuracy: 0.2347\n",
      "Epoch 72/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -886564480.0000 - accuracy: 0.2347 - val_loss: -882062784.0000 - val_accuracy: 0.2347\n",
      "Epoch 73/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -913233024.0000 - accuracy: 0.2347 - val_loss: -908127808.0000 - val_accuracy: 0.2347\n",
      "Epoch 74/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -940062656.0000 - accuracy: 0.2347 - val_loss: -935081984.0000 - val_accuracy: 0.2347\n",
      "Epoch 75/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -967258112.0000 - accuracy: 0.2347 - val_loss: -962267264.0000 - val_accuracy: 0.2347\n",
      "Epoch 76/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -995176384.0000 - accuracy: 0.2347 - val_loss: -989353024.0000 - val_accuracy: 0.2347\n",
      "Epoch 77/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1023386304.0000 - accuracy: 0.2347 - val_loss: -1017589376.0000 - val_accuracy: 0.2347\n",
      "Epoch 78/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1052220096.0000 - accuracy: 0.2347 - val_loss: -1045721536.0000 - val_accuracy: 0.2347\n",
      "Epoch 79/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1081702144.0000 - accuracy: 0.2347 - val_loss: -1074458624.0000 - val_accuracy: 0.2347\n",
      "Epoch 80/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1111444224.0000 - accuracy: 0.2347 - val_loss: -1103907072.0000 - val_accuracy: 0.2347\n",
      "Epoch 81/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1141404800.0000 - accuracy: 0.2347 - val_loss: -1134287488.0000 - val_accuracy: 0.2347\n",
      "Epoch 82/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1172238848.0000 - accuracy: 0.2347 - val_loss: -1164327424.0000 - val_accuracy: 0.2347\n",
      "Epoch 83/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1203406208.0000 - accuracy: 0.2347 - val_loss: -1195187584.0000 - val_accuracy: 0.2347\n",
      "Epoch 84/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1234998912.0000 - accuracy: 0.2347 - val_loss: -1226255488.0000 - val_accuracy: 0.2347\n",
      "Epoch 85/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1266969728.0000 - accuracy: 0.2347 - val_loss: -1258049408.0000 - val_accuracy: 0.2347\n",
      "Epoch 86/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1299680512.0000 - accuracy: 0.2347 - val_loss: -1290400384.0000 - val_accuracy: 0.2347\n",
      "Epoch 87/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1332829952.0000 - accuracy: 0.2347 - val_loss: -1323051520.0000 - val_accuracy: 0.2347\n",
      "Epoch 88/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1366252672.0000 - accuracy: 0.2347 - val_loss: -1356083200.0000 - val_accuracy: 0.2347\n",
      "Epoch 89/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1400059520.0000 - accuracy: 0.2347 - val_loss: -1389385600.0000 - val_accuracy: 0.2347\n",
      "Epoch 90/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1434620544.0000 - accuracy: 0.2347 - val_loss: -1423657728.0000 - val_accuracy: 0.2347\n",
      "Epoch 91/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1469688448.0000 - accuracy: 0.2347 - val_loss: -1458068352.0000 - val_accuracy: 0.2347\n",
      "Epoch 92/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1504951936.0000 - accuracy: 0.2347 - val_loss: -1493271168.0000 - val_accuracy: 0.2347\n",
      "Epoch 93/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1541245184.0000 - accuracy: 0.2347 - val_loss: -1528253056.0000 - val_accuracy: 0.2347\n",
      "Epoch 94/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1577931392.0000 - accuracy: 0.2347 - val_loss: -1565183744.0000 - val_accuracy: 0.2347\n",
      "Epoch 95/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1615024896.0000 - accuracy: 0.2347 - val_loss: -1601934592.0000 - val_accuracy: 0.2347\n",
      "Epoch 96/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1652768512.0000 - accuracy: 0.2347 - val_loss: -1638598016.0000 - val_accuracy: 0.2347\n",
      "Epoch 97/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1690827008.0000 - accuracy: 0.2347 - val_loss: -1676418944.0000 - val_accuracy: 0.2347\n",
      "Epoch 98/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1729434752.0000 - accuracy: 0.2347 - val_loss: -1714358016.0000 - val_accuracy: 0.2347\n",
      "Epoch 99/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1767997824.0000 - accuracy: 0.2347 - val_loss: -1752524416.0000 - val_accuracy: 0.2347\n",
      "Epoch 100/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1807741312.0000 - accuracy: 0.2347 - val_loss: -1791259136.0000 - val_accuracy: 0.2347\n",
      "Epoch 101/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1847820160.0000 - accuracy: 0.2347 - val_loss: -1831407104.0000 - val_accuracy: 0.2347\n",
      "Epoch 102/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1888501760.0000 - accuracy: 0.2347 - val_loss: -1870506240.0000 - val_accuracy: 0.2347\n",
      "Epoch 103/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1929247360.0000 - accuracy: 0.2347 - val_loss: -1911723904.0000 - val_accuracy: 0.2347\n",
      "Epoch 104/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -1971348864.0000 - accuracy: 0.2347 - val_loss: -1952834176.0000 - val_accuracy: 0.2347\n",
      "Epoch 105/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2013546240.0000 - accuracy: 0.2347 - val_loss: -1994118656.0000 - val_accuracy: 0.2347\n",
      "Epoch 106/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2056233984.0000 - accuracy: 0.2347 - val_loss: -2037135232.0000 - val_accuracy: 0.2347\n",
      "Epoch 107/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2099597440.0000 - accuracy: 0.2347 - val_loss: -2080140800.0000 - val_accuracy: 0.2347\n",
      "Epoch 108/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2143846400.0000 - accuracy: 0.2347 - val_loss: -2123245312.0000 - val_accuracy: 0.2347\n",
      "Epoch 109/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2188067328.0000 - accuracy: 0.2347 - val_loss: -2166978304.0000 - val_accuracy: 0.2347\n",
      "Epoch 110/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2233477120.0000 - accuracy: 0.2347 - val_loss: -2210850816.0000 - val_accuracy: 0.2347\n",
      "Epoch 111/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2278937344.0000 - accuracy: 0.2347 - val_loss: -2256346368.0000 - val_accuracy: 0.2347\n",
      "Epoch 112/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2325185792.0000 - accuracy: 0.2347 - val_loss: -2301870080.0000 - val_accuracy: 0.2347\n",
      "Epoch 113/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2371726080.0000 - accuracy: 0.2347 - val_loss: -2348756992.0000 - val_accuracy: 0.2347\n",
      "Epoch 114/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2419439616.0000 - accuracy: 0.2347 - val_loss: -2395001856.0000 - val_accuracy: 0.2347\n",
      "Epoch 115/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2467495936.0000 - accuracy: 0.2347 - val_loss: -2442265856.0000 - val_accuracy: 0.2347\n",
      "Epoch 116/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2515988736.0000 - accuracy: 0.2347 - val_loss: -2489946112.0000 - val_accuracy: 0.2347\n",
      "Epoch 117/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2564762112.0000 - accuracy: 0.2347 - val_loss: -2538408704.0000 - val_accuracy: 0.2347\n",
      "Epoch 118/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2614210048.0000 - accuracy: 0.2347 - val_loss: -2587348736.0000 - val_accuracy: 0.2347\n",
      "Epoch 119/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2664439552.0000 - accuracy: 0.2347 - val_loss: -2635125760.0000 - val_accuracy: 0.2347\n",
      "Epoch 120/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2714878464.0000 - accuracy: 0.2347 - val_loss: -2687026176.0000 - val_accuracy: 0.2347\n",
      "Epoch 121/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2766478592.0000 - accuracy: 0.2347 - val_loss: -2737511424.0000 - val_accuracy: 0.2347\n",
      "Epoch 122/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2818267392.0000 - accuracy: 0.2347 - val_loss: -2787273984.0000 - val_accuracy: 0.2347\n",
      "Epoch 123/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2870991104.0000 - accuracy: 0.2347 - val_loss: -2839934208.0000 - val_accuracy: 0.2347\n",
      "Epoch 124/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2924064768.0000 - accuracy: 0.2347 - val_loss: -2892366592.0000 - val_accuracy: 0.2347\n",
      "Epoch 125/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -2977720320.0000 - accuracy: 0.2347 - val_loss: -2945153536.0000 - val_accuracy: 0.2347\n",
      "Epoch 126/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3032229376.0000 - accuracy: 0.2347 - val_loss: -2998987008.0000 - val_accuracy: 0.2347\n",
      "Epoch 127/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3087297024.0000 - accuracy: 0.2347 - val_loss: -3052515584.0000 - val_accuracy: 0.2347\n",
      "Epoch 128/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3142997760.0000 - accuracy: 0.2347 - val_loss: -3108491776.0000 - val_accuracy: 0.2347\n",
      "Epoch 129/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3199261696.0000 - accuracy: 0.2347 - val_loss: -3164207104.0000 - val_accuracy: 0.2347\n",
      "Epoch 130/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3256462336.0000 - accuracy: 0.2347 - val_loss: -3218999552.0000 - val_accuracy: 0.2347\n",
      "Epoch 131/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3313386240.0000 - accuracy: 0.2347 - val_loss: -3276372224.0000 - val_accuracy: 0.2347\n",
      "Epoch 132/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3372397568.0000 - accuracy: 0.2347 - val_loss: -3333946112.0000 - val_accuracy: 0.2347\n",
      "Epoch 133/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3431927808.0000 - accuracy: 0.2347 - val_loss: -3391915264.0000 - val_accuracy: 0.2347\n",
      "Epoch 134/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3491429120.0000 - accuracy: 0.2347 - val_loss: -3451458304.0000 - val_accuracy: 0.2347\n",
      "Epoch 135/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3551300864.0000 - accuracy: 0.2347 - val_loss: -3509456384.0000 - val_accuracy: 0.2347\n",
      "Epoch 136/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3611303168.0000 - accuracy: 0.2347 - val_loss: -3568749824.0000 - val_accuracy: 0.2347\n",
      "Epoch 137/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3672455168.0000 - accuracy: 0.2347 - val_loss: -3630033408.0000 - val_accuracy: 0.2347\n",
      "Epoch 138/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3734593792.0000 - accuracy: 0.2347 - val_loss: -3691243776.0000 - val_accuracy: 0.2347\n",
      "Epoch 139/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3796790272.0000 - accuracy: 0.2347 - val_loss: -3750923008.0000 - val_accuracy: 0.2347\n",
      "Epoch 140/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3859410944.0000 - accuracy: 0.2347 - val_loss: -3813364736.0000 - val_accuracy: 0.2347\n",
      "Epoch 141/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3923100416.0000 - accuracy: 0.2347 - val_loss: -3876809472.0000 - val_accuracy: 0.2347\n",
      "Epoch 142/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -3987148288.0000 - accuracy: 0.2347 - val_loss: -3940285184.0000 - val_accuracy: 0.2347\n",
      "Epoch 143/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4052027392.0000 - accuracy: 0.2347 - val_loss: -4003357952.0000 - val_accuracy: 0.2347\n",
      "Epoch 144/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4117413376.0000 - accuracy: 0.2347 - val_loss: -4069311488.0000 - val_accuracy: 0.2347\n",
      "Epoch 145/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4184551936.0000 - accuracy: 0.2347 - val_loss: -4133466880.0000 - val_accuracy: 0.2347\n",
      "Epoch 146/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4251312640.0000 - accuracy: 0.2347 - val_loss: -4198846976.0000 - val_accuracy: 0.2347\n",
      "Epoch 147/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4318214656.0000 - accuracy: 0.2347 - val_loss: -4266745856.0000 - val_accuracy: 0.2347\n",
      "Epoch 148/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4387000832.0000 - accuracy: 0.2347 - val_loss: -4332519936.0000 - val_accuracy: 0.2347\n",
      "Epoch 149/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4455401984.0000 - accuracy: 0.2347 - val_loss: -4400797696.0000 - val_accuracy: 0.2347\n",
      "Epoch 150/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4524887040.0000 - accuracy: 0.2347 - val_loss: -4469413376.0000 - val_accuracy: 0.2347\n",
      "Epoch 151/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4595273728.0000 - accuracy: 0.2347 - val_loss: -4536822272.0000 - val_accuracy: 0.2347\n",
      "Epoch 152/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4665536000.0000 - accuracy: 0.2347 - val_loss: -4608172032.0000 - val_accuracy: 0.2347\n",
      "Epoch 153/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4737241600.0000 - accuracy: 0.2347 - val_loss: -4678697984.0000 - val_accuracy: 0.2347\n",
      "Epoch 154/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4809415168.0000 - accuracy: 0.2347 - val_loss: -4748688384.0000 - val_accuracy: 0.2347\n",
      "Epoch 155/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4882382336.0000 - accuracy: 0.2347 - val_loss: -4820210176.0000 - val_accuracy: 0.2347\n",
      "Epoch 156/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -4955282432.0000 - accuracy: 0.2347 - val_loss: -4894742016.0000 - val_accuracy: 0.2347\n",
      "Epoch 157/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5029832192.0000 - accuracy: 0.2347 - val_loss: -4965383680.0000 - val_accuracy: 0.2347\n",
      "Epoch 158/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5104861184.0000 - accuracy: 0.2347 - val_loss: -5040844288.0000 - val_accuracy: 0.2347\n",
      "Epoch 159/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5180962304.0000 - accuracy: 0.2347 - val_loss: -5114426880.0000 - val_accuracy: 0.2347\n",
      "Epoch 160/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5257173504.0000 - accuracy: 0.2347 - val_loss: -5190772736.0000 - val_accuracy: 0.2347\n",
      "Epoch 161/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5333825024.0000 - accuracy: 0.2347 - val_loss: -5265193472.0000 - val_accuracy: 0.2347\n",
      "Epoch 162/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5410831872.0000 - accuracy: 0.2347 - val_loss: -5341426176.0000 - val_accuracy: 0.2347\n",
      "Epoch 163/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5488896000.0000 - accuracy: 0.2347 - val_loss: -5417869312.0000 - val_accuracy: 0.2347\n",
      "Epoch 164/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5568294400.0000 - accuracy: 0.2347 - val_loss: -5496082944.0000 - val_accuracy: 0.2347\n",
      "Epoch 165/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5648145408.0000 - accuracy: 0.2347 - val_loss: -5574950912.0000 - val_accuracy: 0.2347\n",
      "Epoch 166/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5728428544.0000 - accuracy: 0.2347 - val_loss: -5653662208.0000 - val_accuracy: 0.2347\n",
      "Epoch 167/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5809323008.0000 - accuracy: 0.2347 - val_loss: -5733563392.0000 - val_accuracy: 0.2347\n",
      "Epoch 168/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5891128320.0000 - accuracy: 0.2347 - val_loss: -5814723072.0000 - val_accuracy: 0.2347\n",
      "Epoch 169/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -5974375424.0000 - accuracy: 0.2347 - val_loss: -5895437312.0000 - val_accuracy: 0.2347\n",
      "Epoch 170/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6056733696.0000 - accuracy: 0.2347 - val_loss: -5975695360.0000 - val_accuracy: 0.2347\n",
      "Epoch 171/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6140967424.0000 - accuracy: 0.2347 - val_loss: -6059496448.0000 - val_accuracy: 0.2347\n",
      "Epoch 172/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6225945088.0000 - accuracy: 0.2347 - val_loss: -6142164992.0000 - val_accuracy: 0.2347\n",
      "Epoch 173/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6310945792.0000 - accuracy: 0.2347 - val_loss: -6228040704.0000 - val_accuracy: 0.2347\n",
      "Epoch 174/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6396516352.0000 - accuracy: 0.2347 - val_loss: -6311521280.0000 - val_accuracy: 0.2347\n",
      "Epoch 175/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6482325504.0000 - accuracy: 0.2347 - val_loss: -6394379776.0000 - val_accuracy: 0.2347\n",
      "Epoch 176/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6568849920.0000 - accuracy: 0.2347 - val_loss: -6481271296.0000 - val_accuracy: 0.2347\n",
      "Epoch 177/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6657306112.0000 - accuracy: 0.2347 - val_loss: -6567043072.0000 - val_accuracy: 0.2347\n",
      "Epoch 178/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6745629696.0000 - accuracy: 0.2347 - val_loss: -6655499264.0000 - val_accuracy: 0.2347\n",
      "Epoch 179/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6834701312.0000 - accuracy: 0.2347 - val_loss: -6742248448.0000 - val_accuracy: 0.2347\n",
      "Epoch 180/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -6923857408.0000 - accuracy: 0.2347 - val_loss: -6829904896.0000 - val_accuracy: 0.2347\n",
      "Epoch 181/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7014990336.0000 - accuracy: 0.2347 - val_loss: -6920676352.0000 - val_accuracy: 0.2347\n",
      "Epoch 182/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7106998784.0000 - accuracy: 0.2347 - val_loss: -7009643520.0000 - val_accuracy: 0.2347\n",
      "Epoch 183/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7199287808.0000 - accuracy: 0.2347 - val_loss: -7100819968.0000 - val_accuracy: 0.2347\n",
      "Epoch 184/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7291765760.0000 - accuracy: 0.2347 - val_loss: -7192060928.0000 - val_accuracy: 0.2347\n",
      "Epoch 185/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7385516544.0000 - accuracy: 0.2347 - val_loss: -7285548544.0000 - val_accuracy: 0.2347\n",
      "Epoch 186/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7480847360.0000 - accuracy: 0.2347 - val_loss: -7378754048.0000 - val_accuracy: 0.2347\n",
      "Epoch 187/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7576385024.0000 - accuracy: 0.2347 - val_loss: -7472612864.0000 - val_accuracy: 0.2347\n",
      "Epoch 188/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7672076288.0000 - accuracy: 0.2347 - val_loss: -7567707136.0000 - val_accuracy: 0.2347\n",
      "Epoch 189/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7768575488.0000 - accuracy: 0.2347 - val_loss: -7660721664.0000 - val_accuracy: 0.2347\n",
      "Epoch 190/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7865433088.0000 - accuracy: 0.2347 - val_loss: -7754871808.0000 - val_accuracy: 0.2347\n",
      "Epoch 191/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -7963647488.0000 - accuracy: 0.2347 - val_loss: -7852890112.0000 - val_accuracy: 0.2347\n",
      "Epoch 192/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8062809088.0000 - accuracy: 0.2347 - val_loss: -7949758976.0000 - val_accuracy: 0.2347\n",
      "Epoch 193/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8162925056.0000 - accuracy: 0.2347 - val_loss: -8048814080.0000 - val_accuracy: 0.2347\n",
      "Epoch 194/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8262487040.0000 - accuracy: 0.2347 - val_loss: -8148210688.0000 - val_accuracy: 0.2347\n",
      "Epoch 195/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8363148288.0000 - accuracy: 0.2347 - val_loss: -8247582720.0000 - val_accuracy: 0.2347\n",
      "Epoch 196/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8464875520.0000 - accuracy: 0.2347 - val_loss: -8346806784.0000 - val_accuracy: 0.2347\n",
      "Epoch 197/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8568289280.0000 - accuracy: 0.2347 - val_loss: -8447291392.0000 - val_accuracy: 0.2347\n",
      "Epoch 198/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8671203328.0000 - accuracy: 0.2347 - val_loss: -8548748800.0000 - val_accuracy: 0.2347\n",
      "Epoch 199/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8776119296.0000 - accuracy: 0.2347 - val_loss: -8652775424.0000 - val_accuracy: 0.2347\n",
      "Epoch 200/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8881662976.0000 - accuracy: 0.2347 - val_loss: -8754475008.0000 - val_accuracy: 0.2347\n",
      "Epoch 201/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -8987082752.0000 - accuracy: 0.2347 - val_loss: -8861705216.0000 - val_accuracy: 0.2347\n",
      "Epoch 202/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -9095409664.0000 - accuracy: 0.2347 - val_loss: -8965954560.0000 - val_accuracy: 0.2347\n",
      "Epoch 203/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -9202922496.0000 - accuracy: 0.2347 - val_loss: -9070645248.0000 - val_accuracy: 0.2347\n",
      "Epoch 204/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -9311464448.0000 - accuracy: 0.2347 - val_loss: -9181444096.0000 - val_accuracy: 0.2347\n",
      "Epoch 205/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -9422199808.0000 - accuracy: 0.2347 - val_loss: -9286595584.0000 - val_accuracy: 0.2347\n",
      "Epoch 206/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -9531741184.0000 - accuracy: 0.2347 - val_loss: -9395256320.0000 - val_accuracy: 0.2347\n",
      "Epoch 207/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -9644043264.0000 - accuracy: 0.2347 - val_loss: -9506634752.0000 - val_accuracy: 0.2347\n",
      "Epoch 208/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -9755468800.0000 - accuracy: 0.2347 - val_loss: -9616186368.0000 - val_accuracy: 0.2347\n",
      "Epoch 209/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -9867788288.0000 - accuracy: 0.2347 - val_loss: -9727509504.0000 - val_accuracy: 0.2347\n",
      "Epoch 210/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -9981608960.0000 - accuracy: 0.2347 - val_loss: -9837181952.0000 - val_accuracy: 0.2347\n",
      "Epoch 211/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -10095921152.0000 - accuracy: 0.2347 - val_loss: -9950620672.0000 - val_accuracy: 0.2347\n",
      "Epoch 212/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -10212363264.0000 - accuracy: 0.2347 - val_loss: -10064239616.0000 - val_accuracy: 0.2347\n",
      "Epoch 213/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -10328840192.0000 - accuracy: 0.2347 - val_loss: -10179057664.0000 - val_accuracy: 0.2347\n",
      "Epoch 214/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -10444546048.0000 - accuracy: 0.2347 - val_loss: -10292546560.0000 - val_accuracy: 0.2347\n",
      "Epoch 215/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -10561875968.0000 - accuracy: 0.2347 - val_loss: -10408604672.0000 - val_accuracy: 0.2347\n",
      "Epoch 216/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -10680204288.0000 - accuracy: 0.2347 - val_loss: -10527191040.0000 - val_accuracy: 0.2347\n",
      "Epoch 217/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -10799570944.0000 - accuracy: 0.2347 - val_loss: -10642202624.0000 - val_accuracy: 0.2347\n",
      "Epoch 218/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -10918935552.0000 - accuracy: 0.2347 - val_loss: -10760629248.0000 - val_accuracy: 0.2347\n",
      "Epoch 219/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -11038917632.0000 - accuracy: 0.2347 - val_loss: -10875013120.0000 - val_accuracy: 0.2347\n",
      "Epoch 220/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -11159306240.0000 - accuracy: 0.2347 - val_loss: -10999050240.0000 - val_accuracy: 0.2347\n",
      "Epoch 221/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -11282728960.0000 - accuracy: 0.2347 - val_loss: -11116618752.0000 - val_accuracy: 0.2347\n",
      "Epoch 222/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -11406191616.0000 - accuracy: 0.2347 - val_loss: -11239282688.0000 - val_accuracy: 0.2347\n",
      "Epoch 223/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -11529577472.0000 - accuracy: 0.2347 - val_loss: -11360352256.0000 - val_accuracy: 0.2347\n",
      "Epoch 224/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -11654360064.0000 - accuracy: 0.2347 - val_loss: -11482406912.0000 - val_accuracy: 0.2347\n",
      "Epoch 225/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -11780463616.0000 - accuracy: 0.2347 - val_loss: -11608556544.0000 - val_accuracy: 0.2347\n",
      "Epoch 226/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -11908031488.0000 - accuracy: 0.2347 - val_loss: -11730615296.0000 - val_accuracy: 0.2347\n",
      "Epoch 227/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -12033550336.0000 - accuracy: 0.2347 - val_loss: -11855903744.0000 - val_accuracy: 0.2347\n",
      "Epoch 228/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -12161601536.0000 - accuracy: 0.2347 - val_loss: -11983623168.0000 - val_accuracy: 0.2347\n",
      "Epoch 229/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -12291375104.0000 - accuracy: 0.2347 - val_loss: -12108463104.0000 - val_accuracy: 0.2347\n",
      "Epoch 230/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -12421342208.0000 - accuracy: 0.2347 - val_loss: -12237044736.0000 - val_accuracy: 0.2347\n",
      "Epoch 231/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -12552585216.0000 - accuracy: 0.2347 - val_loss: -12366865408.0000 - val_accuracy: 0.2347\n",
      "Epoch 232/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -12684449792.0000 - accuracy: 0.2347 - val_loss: -12496736256.0000 - val_accuracy: 0.2347\n",
      "Epoch 233/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -12816972800.0000 - accuracy: 0.2347 - val_loss: -12626135040.0000 - val_accuracy: 0.2347\n",
      "Epoch 234/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -12951083008.0000 - accuracy: 0.2347 - val_loss: -12756444160.0000 - val_accuracy: 0.2347\n",
      "Epoch 235/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -13084720128.0000 - accuracy: 0.2347 - val_loss: -12889674752.0000 - val_accuracy: 0.2347\n",
      "Epoch 236/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -13220443136.0000 - accuracy: 0.2347 - val_loss: -13023011840.0000 - val_accuracy: 0.2347\n",
      "Epoch 237/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -13356440576.0000 - accuracy: 0.2347 - val_loss: -13156050944.0000 - val_accuracy: 0.2347\n",
      "Epoch 238/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -13493566464.0000 - accuracy: 0.2347 - val_loss: -13291786240.0000 - val_accuracy: 0.2347\n",
      "Epoch 239/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -13630652416.0000 - accuracy: 0.2347 - val_loss: -13428254720.0000 - val_accuracy: 0.2347\n",
      "Epoch 240/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -13770293248.0000 - accuracy: 0.2347 - val_loss: -13563826176.0000 - val_accuracy: 0.2347\n",
      "Epoch 241/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -13909185536.0000 - accuracy: 0.2347 - val_loss: -13701849088.0000 - val_accuracy: 0.2347\n",
      "Epoch 242/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -14050059264.0000 - accuracy: 0.2347 - val_loss: -13840359424.0000 - val_accuracy: 0.2347\n",
      "Epoch 243/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -14191956992.0000 - accuracy: 0.2347 - val_loss: -13980018688.0000 - val_accuracy: 0.2347\n",
      "Epoch 244/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -14334999552.0000 - accuracy: 0.2347 - val_loss: -14119017472.0000 - val_accuracy: 0.2347\n",
      "Epoch 245/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -14478620672.0000 - accuracy: 0.2347 - val_loss: -14260932608.0000 - val_accuracy: 0.2347\n",
      "Epoch 246/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -14624094208.0000 - accuracy: 0.2347 - val_loss: -14405032960.0000 - val_accuracy: 0.2347\n",
      "Epoch 247/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -14770288640.0000 - accuracy: 0.2347 - val_loss: -14546587648.0000 - val_accuracy: 0.2347\n",
      "Epoch 248/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -14916697088.0000 - accuracy: 0.2347 - val_loss: -14690208768.0000 - val_accuracy: 0.2347\n",
      "Epoch 249/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -15063869440.0000 - accuracy: 0.2347 - val_loss: -14834707456.0000 - val_accuracy: 0.2347\n",
      "Epoch 250/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -15210655744.0000 - accuracy: 0.2347 - val_loss: -14979941376.0000 - val_accuracy: 0.2347\n",
      "Epoch 251/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -15360861184.0000 - accuracy: 0.2347 - val_loss: -15129418752.0000 - val_accuracy: 0.2347\n",
      "Epoch 252/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -15511880704.0000 - accuracy: 0.2347 - val_loss: -15275817984.0000 - val_accuracy: 0.2347\n",
      "Epoch 253/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -15662434304.0000 - accuracy: 0.2347 - val_loss: -15424020480.0000 - val_accuracy: 0.2347\n",
      "Epoch 254/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -15814208512.0000 - accuracy: 0.2347 - val_loss: -15574204416.0000 - val_accuracy: 0.2347\n",
      "Epoch 255/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -15966850048.0000 - accuracy: 0.2347 - val_loss: -15725011968.0000 - val_accuracy: 0.2347\n",
      "Epoch 256/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -16120945664.0000 - accuracy: 0.2347 - val_loss: -15876939776.0000 - val_accuracy: 0.2347\n",
      "Epoch 257/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -16275846144.0000 - accuracy: 0.2347 - val_loss: -16028748800.0000 - val_accuracy: 0.2347\n",
      "Epoch 258/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -16432379904.0000 - accuracy: 0.2347 - val_loss: -16180008960.0000 - val_accuracy: 0.2347\n",
      "Epoch 259/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -16589134848.0000 - accuracy: 0.2347 - val_loss: -16335921152.0000 - val_accuracy: 0.2347\n",
      "Epoch 260/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -16748359680.0000 - accuracy: 0.2347 - val_loss: -16491429888.0000 - val_accuracy: 0.2347\n",
      "Epoch 261/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -16907961344.0000 - accuracy: 0.2347 - val_loss: -16650182656.0000 - val_accuracy: 0.2347\n",
      "Epoch 262/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -17068409856.0000 - accuracy: 0.2347 - val_loss: -16806462464.0000 - val_accuracy: 0.2347\n",
      "Epoch 263/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -17228400640.0000 - accuracy: 0.2347 - val_loss: -16962946048.0000 - val_accuracy: 0.2347\n",
      "Epoch 264/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -17390366720.0000 - accuracy: 0.2347 - val_loss: -17120949248.0000 - val_accuracy: 0.2347\n",
      "Epoch 265/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -17553545216.0000 - accuracy: 0.2347 - val_loss: -17282226176.0000 - val_accuracy: 0.2347\n",
      "Epoch 266/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -17717897216.0000 - accuracy: 0.2347 - val_loss: -17447514112.0000 - val_accuracy: 0.2347\n",
      "Epoch 267/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -17883701248.0000 - accuracy: 0.2347 - val_loss: -17608826880.0000 - val_accuracy: 0.2347\n",
      "Epoch 268/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -18049382400.0000 - accuracy: 0.2347 - val_loss: -17768800256.0000 - val_accuracy: 0.2347\n",
      "Epoch 269/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -18215352320.0000 - accuracy: 0.2347 - val_loss: -17934874624.0000 - val_accuracy: 0.2347\n",
      "Epoch 270/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -18382985216.0000 - accuracy: 0.2347 - val_loss: -18097225728.0000 - val_accuracy: 0.2347\n",
      "Epoch 271/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -18552193024.0000 - accuracy: 0.2347 - val_loss: -18264946688.0000 - val_accuracy: 0.2347\n",
      "Epoch 272/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -18721474560.0000 - accuracy: 0.2347 - val_loss: -18430502912.0000 - val_accuracy: 0.2347\n",
      "Epoch 273/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -18891433984.0000 - accuracy: 0.2347 - val_loss: -18599888896.0000 - val_accuracy: 0.2347\n",
      "Epoch 274/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -19063265280.0000 - accuracy: 0.2347 - val_loss: -18765561856.0000 - val_accuracy: 0.2347\n",
      "Epoch 275/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -19234398208.0000 - accuracy: 0.2347 - val_loss: -18936981504.0000 - val_accuracy: 0.2347\n",
      "Epoch 276/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -19408867328.0000 - accuracy: 0.2347 - val_loss: -19106531328.0000 - val_accuracy: 0.2347\n",
      "Epoch 277/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -19583240192.0000 - accuracy: 0.2347 - val_loss: -19278919680.0000 - val_accuracy: 0.2347\n",
      "Epoch 278/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -19758596096.0000 - accuracy: 0.2347 - val_loss: -19450566656.0000 - val_accuracy: 0.2347\n",
      "Epoch 279/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -19934087168.0000 - accuracy: 0.2347 - val_loss: -19624466432.0000 - val_accuracy: 0.2347\n",
      "Epoch 280/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -20111204352.0000 - accuracy: 0.2347 - val_loss: -19797602304.0000 - val_accuracy: 0.2347\n",
      "Epoch 281/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -20289206272.0000 - accuracy: 0.2347 - val_loss: -19974758400.0000 - val_accuracy: 0.2347\n",
      "Epoch 282/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -20469073920.0000 - accuracy: 0.2347 - val_loss: -20147208192.0000 - val_accuracy: 0.2347\n",
      "Epoch 283/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -20650336256.0000 - accuracy: 0.2347 - val_loss: -20326289408.0000 - val_accuracy: 0.2347\n",
      "Epoch 284/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -20832626688.0000 - accuracy: 0.2347 - val_loss: -20508766208.0000 - val_accuracy: 0.2347\n",
      "Epoch 285/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -21017034752.0000 - accuracy: 0.2347 - val_loss: -20682653696.0000 - val_accuracy: 0.2347\n",
      "Epoch 286/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -21199294464.0000 - accuracy: 0.2347 - val_loss: -20870178816.0000 - val_accuracy: 0.2347\n",
      "Epoch 287/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -21384552448.0000 - accuracy: 0.2347 - val_loss: -21049145344.0000 - val_accuracy: 0.2347\n",
      "Epoch 288/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -21568974848.0000 - accuracy: 0.2347 - val_loss: -21230010368.0000 - val_accuracy: 0.2347\n",
      "Epoch 289/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -21755965440.0000 - accuracy: 0.2347 - val_loss: -21411368960.0000 - val_accuracy: 0.2347\n",
      "Epoch 290/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -21943824384.0000 - accuracy: 0.2347 - val_loss: -21596418048.0000 - val_accuracy: 0.2347\n",
      "Epoch 291/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -22134153216.0000 - accuracy: 0.2347 - val_loss: -21785346048.0000 - val_accuracy: 0.2347\n",
      "Epoch 292/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -22324082688.0000 - accuracy: 0.2347 - val_loss: -21969684480.0000 - val_accuracy: 0.2347\n",
      "Epoch 293/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -22513809408.0000 - accuracy: 0.2347 - val_loss: -22158862336.0000 - val_accuracy: 0.2347\n",
      "Epoch 294/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -22706569216.0000 - accuracy: 0.2347 - val_loss: -22347132928.0000 - val_accuracy: 0.2347\n",
      "Epoch 295/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -22898911232.0000 - accuracy: 0.2347 - val_loss: -22536400896.0000 - val_accuracy: 0.2347\n",
      "Epoch 296/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -23092475904.0000 - accuracy: 0.2347 - val_loss: -22727860224.0000 - val_accuracy: 0.2347\n",
      "Epoch 297/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -23285686272.0000 - accuracy: 0.2347 - val_loss: -22915805184.0000 - val_accuracy: 0.2347\n",
      "Epoch 298/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -23480500224.0000 - accuracy: 0.2347 - val_loss: -23109941248.0000 - val_accuracy: 0.2347\n",
      "Epoch 299/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -23678048256.0000 - accuracy: 0.2347 - val_loss: -23304267776.0000 - val_accuracy: 0.2347\n",
      "Epoch 300/300\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -23877978112.0000 - accuracy: 0.2347 - val_loss: -23496910848.0000 - val_accuracy: 0.2347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e9aff6440>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=300, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/pose_estimation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = [814.3917846679688,295.0393981933594,0.9929024577140808,830.705078125,275.5037841796875,0.9831287264823914,791.8114624023438,283.0101318359375,0.9574829936027527,865.8885498046875,287.1263122558594,0.8631071448326111,770.7975463867188,301.5133056640625,0.647434413433075,902.883544921875,405.51507568359375,0.9972906708717346,761.3436279296875,363.00677490234375,0.9956384301185608,949.473876953125,527.3984985351562,0.988193690776825,659.87646484375,263.8723449707031,0.9777438640594482,979.9451904296875,644.51708984375,0.9796992540359497,634.283203125,125.98612976074219,0.9701565504074097,885.6600952148438,621.4949340820312,0.9988512992858887,797.3829345703125,617.8276977539062,0.9984990358352661,942.8157958984375,727.6259155273438,0.997188150882721,836.7139892578125,750.2303466796875,0.9961840510368347,959.1251220703125,970.12060546875,0.9825200438499451,846.7875366210938,972.4566650390625,0.9790786504745483]\n",
    "reshaped_tensor = np.array(tensor).reshape(1, -1)\n",
    "p = model.predict(reshaped_tensor)\n",
    "np.argmax(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
